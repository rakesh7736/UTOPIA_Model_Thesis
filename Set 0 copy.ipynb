{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[H\u001b[2K[##############################] 1/1  (100.0%)\n",
      "\u001b[1BRunning iteration with runName=PE_density900_FI0.7_tHalf1000_hFactor10_tFrag31.6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rakes\\Pictures\\Model\\UTOPIA_model-main\\functions\\RC_generator.py:49: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  t_half_d = float(process_inputs_df.loc[cond, \"thalf_deg_d\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference inflow-outflow = -3.1257513910532e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "c:\\Users\\rakes\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log10\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed run: PE_density900_FI0.7_tHalf1000_hFactor10_tFrag31.6\n",
      "\n",
      "All iterations completed.\n",
      "Comparison data appended to 'Model vs Observed Raw.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "# Emmision on Air\n",
    "\n",
    "import os\n",
    "import math\n",
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# For Spearman correlation\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 1) IMPORT YOUR MODEL FUNCTIONS\n",
    "# -------------------------------------------------------------------\n",
    "# Make sure these paths are correct for your environment\n",
    "from functions import create_inputsTable_UTOPIA\n",
    "from functions.create_rateConstants_tabel import *\n",
    "from functions.fillInteractions_df_fun import *\n",
    "from functions.generate_modelObjects import *\n",
    "from functions.generateRateConstants_particles import *\n",
    "from functions.solver_SteadyState import *\n",
    "from functions.extract_results import *\n",
    "from functions.massBalance import *\n",
    "from functions.exposure_indicators_calculation import *\n",
    "from functions.generate_MPinputs_table import *\n",
    "from functions.save_results import *\n",
    "from functions.loop_CTD_calculation import *\n",
    "from functions.generate_compartmentFlows_tables import *\n",
    "from functions.emission_fractions_calculation import *\n",
    "from helpers.helpers import *\n",
    "\n",
    "#############################################\n",
    "# 2) DEFINE YOUR PARAMETER GRIDS\n",
    "#############################################\n",
    "mpdensity_list = [1100]\n",
    "FI_list = [1]\n",
    "t_half_list = [10000]\n",
    "Input_heter_deg_factor_const = [10]\n",
    "t_frag_list = [100]\n",
    "\n",
    "# Other constant parameters\n",
    "Input_biof_deg_factor = 1/2\n",
    "Input_factor_deepWater_soilSurface = 10\n",
    "Input_factor_sediment = 100\n",
    "Input_biof_frag_factor = 2\n",
    "Input_heter_frag_factor = 100\n",
    "\n",
    "MP_composition = \"PE\"\n",
    "shape = \"sphere\"\n",
    "N_sizeBins = 5\n",
    "big_bin_diameter_um = 5000\n",
    "Input_size_bin = \"e\"\n",
    "Input_MP_form = \"freeMP\"\n",
    "Input_emiss_comp = \"Coast_Surface_Water\"      \n",
    "                                             #\"Ocean_Surface_Water\",\"Ocean_Mixed_Water\",\"Ocean_Column_Water\",\n",
    "                                             #\"Coast_Surface_Water\",\"Coast_Column_Water\",\"Surface_Freshwater\",\n",
    "                                             #\"Bulk_Freshwater\",\"Sediment_Freshwater\",\n",
    "                                             #\"Beaches_Soil_Surface\",Background_Soil_Surface\"\n",
    "                                             #\"Impacted_Soil_Surface\",\"Impacted_Soil\",\"Air\"\n",
    "Input_input_flow_g_s = 250000  # g/s\n",
    "\n",
    "#############################################\n",
    "# 3) SETUP WORKING DIRECTORY, FOLDERS\n",
    "#############################################\n",
    "cwd = os.getcwd()\n",
    "inputs_path = os.path.join(cwd, \"inputs\") + os.sep\n",
    "\n",
    "\n",
    "#new_plots_folder = os.path.join(cwd, \"new plots\")\n",
    "#os.makedirs(new_plots_folder, exist_ok=True)\n",
    "\n",
    "overlay_plots_folder = os.path.join(cwd, \"overlay_plots\")\n",
    "os.makedirs(overlay_plots_folder, exist_ok=True)\n",
    "\n",
    "comparison_excel_file = \"Model vs Observed Raw.xlsx\"\n",
    "\n",
    "#############################################\n",
    "# 4) LOAD OBSERVED DATA\n",
    "#############################################\n",
    "observed_file = \"observed_data_long.xlsx\"\n",
    "observed_df = pd.read_excel(observed_file)\n",
    "\n",
    "observed_df = observed_df.rename(columns={\n",
    "    'dataset identifier': 'Dataset',\n",
    "    'Article name': 'Article',\n",
    "    'log‑transformed size': 'log_Size',\n",
    "    'log‑transformed abundance': 'log_Abundance'\n",
    "})\n",
    "\n",
    "#############################################\n",
    "# 5) DEFINE ARTICLE->COMPARTMENTS MAPPING\n",
    "#############################################\n",
    "overlay_compartments_mapping = {\n",
    "\n",
    "    \"Sea Surface Fibers | Song\": [\"Ocean_Surface_Water\"],\n",
    "   \n",
    "}\n",
    "\n",
    "#############################################\n",
    "# 6) RUN MODEL FOR EACH PARAMETER COMBINATION\n",
    "#############################################\n",
    "comparison_rows = []\n",
    "bar_length = 30\n",
    "iteration_count = 0\n",
    "\n",
    "total_iterations = (\n",
    "    len(mpdensity_list)\n",
    "    * len(FI_list)\n",
    "    * len(t_half_list)\n",
    "    * len(Input_heter_deg_factor_const)\n",
    "    * len(t_frag_list)\n",
    ")\n",
    "\n",
    "# Print an extra blank line so row 0 is free for the bar\n",
    "print(\"\\n\")\n",
    "\n",
    "# Spearman correlation requirement (must be exactly 1.0 in absolute value)\n",
    "# i.e. only consider data with r = ±1. \n",
    "# In practice, we do if abs(r_value) < 1.0: skip\n",
    "spearman_threshold = 1.0\n",
    "\n",
    "for MPdensity_kg_m3 in mpdensity_list:\n",
    "    for Input_FI in FI_list:\n",
    "        for Input_t_half_deg_free in t_half_list:\n",
    "            for heter_deg_factor in Input_heter_deg_factor_const:\n",
    "                for Input_t_frag_gen_FreeSurfaceWater in t_frag_list:\n",
    "\n",
    "                    iteration_count += 1\n",
    "                    # Move cursor to top line, clear it\n",
    "                    sys.stdout.write(\"\\033[H\\033[2K\")\n",
    "\n",
    "                    # Print updated bar\n",
    "                    progress_fraction = iteration_count / total_iterations\n",
    "                    filled = int(bar_length * progress_fraction)\n",
    "                    bar = \"#\" * filled + \"-\" * (bar_length - filled)\n",
    "                    sys.stdout.write(\n",
    "                        f\"[{bar}] {iteration_count}/{total_iterations}  \"\n",
    "                        f\"({progress_fraction*100:.1f}%)\\n\"\n",
    "                    )\n",
    "\n",
    "                    # Move down 1 line to print iteration details\n",
    "                    sys.stdout.write(\"\\033[1B\")\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                    runName = (\n",
    "                        f\"{MP_composition}_density{MPdensity_kg_m3}_\"\n",
    "                        f\"FI{Input_FI}_\"\n",
    "                        f\"tHalf{Input_t_half_deg_free}_\"\n",
    "                        f\"hFactor{heter_deg_factor}_\"\n",
    "                        f\"tFrag{Input_t_frag_gen_FreeSurfaceWater}\"\n",
    "                    )\n",
    "                    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                    print(f\"Running iteration with runName={runName} ...\")\n",
    "\n",
    "                    # --------------------- MODEL CODE SECTION ---------------------\n",
    "                    MP_inputs = {\n",
    "                        \"MP_composition\": MP_composition,\n",
    "                        \"shape\": shape,\n",
    "                        \"N_sizeBins\": N_sizeBins,\n",
    "                        \"big_bin_diameter_um\": big_bin_diameter_um,\n",
    "                        \"runName\": runName,\n",
    "                        \"inputs_path\": inputs_path,\n",
    "                    }\n",
    "                    mp_imputFile_name = write_MPinputs_table(\n",
    "                        MPdensity_kg_m3,\n",
    "                        MP_composition,\n",
    "                        shape,\n",
    "                        N_sizeBins,\n",
    "                        big_bin_diameter_um,\n",
    "                        runName,\n",
    "                        inputs_path,\n",
    "                    )\n",
    "\n",
    "                    v_a = 2.0e-16\n",
    "                    r_a = ((3.0/4.0)*(v_a/math.pi))**(1.0/3.0)\n",
    "                    spm_radius_um = r_a*1e6\n",
    "                    spm_density_kg_m3 = 1388\n",
    "\n",
    "                    comp_impFile_name = \"inputs_compartments.csv\"\n",
    "                    comp_interactFile_name = \"compartment_interactions.csv\"\n",
    "                    boxName = \"Utopia\"\n",
    "                    MPforms_list = [\"freeMP\", \"heterMP\", \"biofMP\", \"heterBiofMP\"]\n",
    "                    (system_particle_object_list,\n",
    "                     SpeciesList,\n",
    "                     spm,\n",
    "                     dict_comp,\n",
    "                     model_lists,\n",
    "                     particles_df) = generate_objects(\n",
    "                        inputs_path,\n",
    "                        boxName=boxName,\n",
    "                        MPforms_list=MPforms_list,\n",
    "                        comp_impFile_name=comp_impFile_name,\n",
    "                        comp_interactFile_name=comp_interactFile_name,\n",
    "                        mp_imputFile_name=mp_imputFile_name,\n",
    "                        spm_radius_um=spm_radius_um,\n",
    "                        spm_density_kg_m3=spm_density_kg_m3,\n",
    "                    )\n",
    "                    surfComp_list = [c for c in dict_comp if \"Surface\" in c]\n",
    "\n",
    "                    frag_styles_dict = {\n",
    "                        0: \"erosive_fragmentation\",\n",
    "                        0.3: \"slightly_mixed\",\n",
    "                        0.5: \"mixed_fragmentation\",\n",
    "                        0.7: \"mostly_sequential\",\n",
    "                        1: \"sequential_fragmentation\"\n",
    "                    }\n",
    "                    FI = Input_FI\n",
    "                    frag_style = frag_styles_dict[FI]\n",
    "\n",
    "                    fsd = generate_fsd_matrix(FI)\n",
    "                    sizes = [list(model_lists[\"dict_size_coding\"].keys())]\n",
    "                    fsd_df = pd.DataFrame(fsd, index=sizes, columns=sizes)\n",
    "                    fsd_filename = os.path.join(inputs_path, \"fsd.csv\")\n",
    "                    fsd_df.to_csv(fsd_filename)\n",
    "\n",
    "                    t_half_deg_free = Input_t_half_deg_free\n",
    "                    biof_deg_factor = Input_biof_deg_factor\n",
    "                    t_half_deg_heter = t_half_deg_free*heter_deg_factor\n",
    "                    t_half_deg_biof = t_half_deg_free*biof_deg_factor\n",
    "                    t_half_deg_biofHeter = t_half_deg_free*biof_deg_factor*heter_deg_factor\n",
    "                    thalf_deg_d_dict = {\n",
    "                        \"freeMP\": t_half_deg_free,\n",
    "                        \"heterMP\": t_half_deg_heter,\n",
    "                        \"biofMP\": t_half_deg_biof,\n",
    "                        \"heterBiofMP\": t_half_deg_biofHeter,\n",
    "                    }\n",
    "\n",
    "                    alpha_heter_filename = os.path.join(inputs_path, \"alpha_heter.csv\")\n",
    "                    alpha_heter_df = pd.read_csv(alpha_heter_filename)\n",
    "                    alpha_hetr_dict = alpha_heter_df.set_index(\"MP_form\")[\"alpha_heter\"].to_dict()\n",
    "\n",
    "                    t_frag_gen_FreeSurfaceWater = Input_t_frag_gen_FreeSurfaceWater\n",
    "\n",
    "                    process_inputs_df = create_inputsTable_UTOPIA(\n",
    "                        inputs_path,\n",
    "                        model_lists,\n",
    "                        thalf_deg_d_dict,\n",
    "                        alpha_hetr_dict,\n",
    "                        t_frag_gen_FreeSurfaceWater,\n",
    "                        Input_biof_frag_factor,\n",
    "                        Input_heter_frag_factor,\n",
    "                        Input_factor_deepWater_soilSurface,\n",
    "                        Input_factor_sediment,\n",
    "                        save_op=\"save\",\n",
    "                    )\n",
    "\n",
    "                    size_codes = [letter for letter in string.ascii_lowercase[0:N_sizeBins]]\n",
    "                    size_dict = dict(zip(size_codes, model_lists[\"dict_size_coding\"].values()))\n",
    "                    particle_forms_coding = dict(zip(MPforms_list, [\"A\", \"B\", \"C\", \"D\"]))\n",
    "                    MP_form_dict_reverse = {v: k for k, v in particle_forms_coding.items()}\n",
    "\n",
    "                    size_bin = Input_size_bin\n",
    "                    MP_form = Input_MP_form\n",
    "                    emiss_comp = Input_emiss_comp\n",
    "                    input_flow_g_s = Input_input_flow_g_s\n",
    "\n",
    "                    q_mass_g_s_dict = {\n",
    "                        \"Ocean_Surface_Water\": 0,\n",
    "                        \"Ocean_Mixed_Water\": 0,\n",
    "                        \"Ocean_Column_Water\": 0,\n",
    "                        \"Coast_Surface_Water\": 0,\n",
    "                        \"Coast_Column_Water\": 0,\n",
    "                        \"Surface_Freshwater\": 0,\n",
    "                        \"Bulk_Freshwater\": 0,\n",
    "                        \"Sediment_Freshwater\": 0,\n",
    "                        \"Sediment_Ocean\": 0,\n",
    "                        \"Sediment_Coast\": 0,\n",
    "                        \"Beaches_Soil_Surface\": 0,\n",
    "                        \"Beaches_Deep_Soil\": 0,\n",
    "                        \"Background_Soil_Surface\": 0,\n",
    "                        \"Background_Soil\": 0,\n",
    "                        \"Impacted_Soil_Surface\": 0,\n",
    "                        \"Impacted_Soil\": 0,\n",
    "                        \"Air\": 0,\n",
    "                    }\n",
    "                    q_mass_g_s_dict[emiss_comp] = input_flow_g_s\n",
    "\n",
    "                    input_flow_filename = os.path.join(inputs_path, \"inputFlows.csv\")\n",
    "                    input_flows_df = pd.DataFrame(\n",
    "                        list(q_mass_g_s_dict.items()), columns=[\"compartment\", \"q_mass_g_s\"]\n",
    "                    )\n",
    "                    input_flows_df.to_csv(input_flow_filename, index=False)\n",
    "\n",
    "                    particle_compartmentCoding = dict(\n",
    "                        zip(\n",
    "                            model_lists[\"compartmentNames_list\"],\n",
    "                            list(range(len(model_lists[\"compartmentNames_list\"]))),\n",
    "                        )\n",
    "                    )\n",
    "                    comp_dict_inverse = {v: k for k, v in particle_compartmentCoding.items()}\n",
    "                    sp_imputs = []\n",
    "                    q_mass_g_s = []\n",
    "                    for compartment in q_mass_g_s_dict.keys():\n",
    "                        sp_imputs.append(\n",
    "                            size_bin\n",
    "                            + particle_forms_coding[MP_form]\n",
    "                            + str(particle_compartmentCoding[compartment])\n",
    "                            + \"_\" + boxName\n",
    "                        )\n",
    "                        q_mass_g_s.append(q_mass_g_s_dict[compartment])\n",
    "                    imput_flows_g_s = dict(zip(sp_imputs, q_mass_g_s))\n",
    "\n",
    "                    q_num_s = [\n",
    "                        mass_to_num(v, p.Pvolume_m3, p.Pdensity_kg_m3) if v != 0 else 0\n",
    "                        for k, v in imput_flows_g_s.items()\n",
    "                        for p in system_particle_object_list\n",
    "                        if k == p.Pcode\n",
    "                    ]\n",
    "\n",
    "                    for particle in system_particle_object_list:\n",
    "                        generate_rateConstants(particle, spm, dict_comp, fsd, process_inputs_df)\n",
    "\n",
    "                    interactions_df = fillInteractions_fun_OOP(system_particle_object_list, SpeciesList, surfComp_list)\n",
    "                    R, PartMass_t0 = solve_ODES_SS(\n",
    "                        system_particle_object_list=system_particle_object_list,\n",
    "                        q_num_s=0,\n",
    "                        imput_flows_g_s=imput_flows_g_s,\n",
    "                        interactions_df=interactions_df,\n",
    "                    )\n",
    "\n",
    "                    R[\"Size_Fraction_um\"] = [size_dict[x[0]] for x in R.index]\n",
    "                    R[\"MP_Form\"] = [MP_form_dict_reverse[x[1]] for x in R.index]\n",
    "                    R[\"Compartment\"] = [comp_dict_inverse[float(x[2:-7])] for x in R.index]\n",
    "                    Results = R[[\n",
    "                        \"Compartment\",\n",
    "                        \"MP_Form\",\n",
    "                        \"Size_Fraction_um\",\n",
    "                        \"mass_g\",\n",
    "                        \"number_of_particles\",\n",
    "                        \"concentration_g_m3\",\n",
    "                        \"concentration_num_m3\",\n",
    "                    ]]\n",
    "\n",
    "                    massBalance(R, system_particle_object_list, q_mass_g_s)\n",
    "\n",
    "                    excluded_sizes = [0.5, 5]\n",
    "                    filtered_Results = Results[~Results['Size_Fraction_um'].isin(excluded_sizes)]\n",
    "                    \n",
    "                    aggregation_columns = {\n",
    "                        'mass_g': 'sum',\n",
    "                        'number_of_particles': 'sum',\n",
    "                        'concentration_g_m3': 'sum',\n",
    "                        'concentration_num_m3': 'sum',\n",
    "                        'mass_fraction': 'sum' if 'mass_fraction' in Results.columns else None,\n",
    "                        'number_fraction': 'sum' if 'number_fraction' in Results.columns else None,\n",
    "                    }\n",
    "                    aggregation_columns = {k: v for k, v in aggregation_columns.items() if v is not None}\n",
    "                    aggregated_results = filtered_Results.groupby(['Compartment', 'Size_Fraction_um']).agg(**{\n",
    "                        col: (col, agg_func) for col, agg_func in aggregation_columns.items()\n",
    "                    }).reset_index()\n",
    "                    \n",
    "                    aggregated_results['relative_abundance'] = aggregated_results.groupby('Compartment')['concentration_num_m3'].transform(\n",
    "                        lambda x: (x / x.sum()) * 100\n",
    "                    )\n",
    "                    aggregated_results['percentage_number_of_particles'] = aggregated_results.groupby('Compartment')['number_of_particles'].transform(\n",
    "                        lambda x: (x / x.sum()) * 100\n",
    "                    )\n",
    "                    \n",
    "                    output_columns_filtered = [\n",
    "                        'Compartment', \n",
    "                        'Size_Fraction_um', \n",
    "                        'mass_g', \n",
    "                        'number_of_particles', \n",
    "                        'percentage_number_of_particles',\n",
    "                        'concentration_g_m3', \n",
    "                        'concentration_num_m3', \n",
    "                        'mass_fraction', \n",
    "                        'number_fraction', \n",
    "                        'relative_abundance'\n",
    "                    ]\n",
    "                    output_columns_filtered = [col for col in output_columns_filtered if col in aggregated_results.columns]\n",
    "                    aggregated_results_output = aggregated_results[output_columns_filtered]\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    compartments = aggregated_results_output['Compartment'].unique()\n",
    "                    for comp in compartments:\n",
    "                        comp_data = aggregated_results_output[aggregated_results_output['Compartment'] == comp]\n",
    "                        comp_data = comp_data[~comp_data['Size_Fraction_um'].isin([0.5, 5])]\n",
    "                        if comp_data.empty:\n",
    "                            continue\n",
    "                        x_vals = np.log10(comp_data['Size_Fraction_um'].astype(float))\n",
    "                        y_vals = np.log10(comp_data['relative_abundance'].astype(float))\n",
    "                        \n",
    "                        #plt.figure()\n",
    "                        #plt.scatter(x_vals, y_vals, color='blue', label=comp)\n",
    "                        #plt.xlabel('log(Size_Fraction_um)')\n",
    "                        #plt.ylabel('log(Relative Abundance (%))')\n",
    "                        #plt.title(f'{comp} - {runName}')\n",
    "                        #plt.legend()\n",
    "                        \n",
    "                        #comp_plot_filename = os.path.join(new_plots_folder, f\"Scatter_{comp}_{runName}_{timestamp}.png\")\n",
    "                        #plt.savefig(comp_plot_filename, bbox_inches=\"tight\")\n",
    "                        #plt.close()\n",
    "\n",
    "                    model_df = aggregated_results_output.copy()\n",
    "                    model_df[\"log_Size\"] = np.log10(model_df[\"Size_Fraction_um\"].astype(float))\n",
    "                    model_df[\"log_RelAbund\"] = np.log10(model_df[\"relative_abundance\"].astype(float))\n",
    "\n",
    "                    for article_name, compartments_list in overlay_compartments_mapping.items():\n",
    "                        obs_subset = observed_df[observed_df[\"Article\"] == article_name]\n",
    "                        if obs_subset.empty:\n",
    "                            continue\n",
    "                        x_obs_all = obs_subset[\"log_Size\"].astype(float).values\n",
    "                        y_obs_all = obs_subset[\"log_Abundance\"].astype(float).values\n",
    "\n",
    "                        slope_obs, intercept_obs = np.nan, np.nan\n",
    "                        x_fit_obs, y_fit_obs = None, None\n",
    "                        if len(x_obs_all) >= 2:\n",
    "                            slope_obs, intercept_obs = np.polyfit(x_obs_all, y_obs_all, 1)\n",
    "                            x_fit_obs = np.linspace(x_obs_all.min(), x_obs_all.max(), 100)\n",
    "                            y_fit_obs = slope_obs * x_fit_obs + intercept_obs\n",
    "\n",
    "                        mod_subset = model_df[model_df[\"Compartment\"].isin(compartments_list)]\n",
    "                        if mod_subset.empty:\n",
    "                            continue\n",
    "\n",
    "                        plt.figure(figsize=(8, 6))\n",
    "                        plt.scatter(x_obs_all, y_obs_all, color='blue', marker='o',\n",
    "                                    label=f\"Observed: {article_name}\")\n",
    "                        if x_fit_obs is not None:\n",
    "                            plt.plot(x_fit_obs, y_fit_obs, color='blue', linestyle='--',\n",
    "                                     label=\"_nolegend_\")\n",
    "\n",
    "                        for comp_name in compartments_list:\n",
    "                            sub_c = mod_subset[mod_subset[\"Compartment\"] == comp_name].copy()\n",
    "                            if sub_c.empty:\n",
    "                                continue\n",
    "\n",
    "                            x_mod_all = sub_c[\"log_Size\"].values\n",
    "                            y_mod_all = sub_c[\"log_RelAbund\"].values\n",
    "\n",
    "                            if len(x_mod_all) < 2:\n",
    "                                # Not enough points to do correlation or slope\n",
    "                                continue\n",
    "\n",
    "                            # Spearman correlation\n",
    "                            r_value, p_value = spearmanr(x_mod_all, y_mod_all)\n",
    "                            if abs(r_value) < spearman_threshold:\n",
    "                                # If abs(r_value) < 1.0, skip\n",
    "                                #print(f\"Skipping {comp_name} in {article_name} due to Spearman r={r_value:.2f}\")\n",
    "                                continue\n",
    "\n",
    "                            # If r=±1.0, proceed\n",
    "                            plt.scatter(x_mod_all, y_mod_all, color='orange', marker='x', label=f\"Model data: {comp_name}\")\n",
    "\n",
    "                            slope_mod, intercept_mod = np.polyfit(x_mod_all, y_mod_all, 1)\n",
    "                            x_fit_mod = np.linspace(x_mod_all.min(), x_mod_all.max(), 100)\n",
    "                            y_fit_mod = slope_mod*x_fit_mod + intercept_mod\n",
    "                            plt.plot(x_fit_mod, y_fit_mod, color='orange', label=\"_nolegend_\")\n",
    "\n",
    "                            if len(x_obs_all) < 2:\n",
    "                                r2 = np.nan\n",
    "                                rmse = np.nan\n",
    "                                euclid_dist = np.nan\n",
    "                                n_points = 0\n",
    "                            else:\n",
    "                                x_min = max(x_obs_all.min(), x_mod_all.min())\n",
    "                                x_max = min(x_obs_all.max(), x_mod_all.max())\n",
    "                                mask_obs = (x_obs_all >= x_min) & (x_obs_all <= x_max)\n",
    "                                x_obs_filt = x_obs_all[mask_obs]\n",
    "                                y_obs_filt = y_obs_all[mask_obs]\n",
    "\n",
    "                                if len(x_obs_filt) < 2:\n",
    "                                    r2 = np.nan\n",
    "                                    rmse = np.nan\n",
    "                                    n_points = len(x_obs_filt)\n",
    "                                else:\n",
    "                                    pred_y = slope_mod*x_obs_filt + intercept_mod\n",
    "                                    ss_res = np.sum((y_obs_filt - pred_y)**2)\n",
    "                                    ss_tot = np.sum((y_obs_filt - y_obs_filt.mean())**2)\n",
    "                                    r2 = 1 - ss_res/ss_tot if ss_tot != 0 else np.nan\n",
    "                                    rmse = np.sqrt(ss_res/len(x_obs_filt))\n",
    "                                    n_points = len(x_obs_filt)\n",
    "\n",
    "                                if not np.isnan(slope_mod) and not np.isnan(slope_obs):\n",
    "                                    euclid_dist = np.sqrt((slope_mod - slope_obs)**2 + (intercept_mod - intercept_obs)**2)\n",
    "                                else:\n",
    "                                    euclid_dist = np.nan\n",
    "\n",
    "                            comparison_rows.append({\n",
    "                                \"Observed Dataset\": article_name,\n",
    "                                \"Model Compartment\": comp_name,\n",
    "                                \"Model slope\": slope_mod,\n",
    "                                \"Observed slope\": slope_obs,\n",
    "                                \"Model intercept\": intercept_mod,\n",
    "                                \"Observed intercept\": intercept_obs,\n",
    "                                \"Euclidean distance\": euclid_dist,\n",
    "                                \"R-squared\": r2,\n",
    "                                \"RMSE\": rmse,\n",
    "                                \"n_points\": n_points,\n",
    "                                \"mini plot\": \"\",\n",
    "                                \"Emissions flow (g/s)\": input_flow_g_s,\n",
    "                                \"Emitted MP density (kg/m3)\": MPdensity_kg_m3,\n",
    "                                \"Receiving compartment/s\": emiss_comp,\n",
    "                                \"Emitted MP form\": MP_form,\n",
    "                                \"Emitted MP size (um)\": size_dict[size_bin],\n",
    "                                \"frag_styles_dict\": FI,\n",
    "                                \"t_half_deg_free\": t_half_deg_free,\n",
    "                                \"heter_deg_factor\": heter_deg_factor,\n",
    "                                \"biof_deg_factor\": Input_biof_deg_factor,\n",
    "                                \"factor_deepWater_soilSurface\": Input_factor_deepWater_soilSurface,\n",
    "                                \"factor_sediment\": Input_factor_sediment,\n",
    "                                \"t_frag_gen_FreeSurfaceWater\": Input_t_frag_gen_FreeSurfaceWater,\n",
    "                                \"biof_frag_factor\": Input_biof_frag_factor,\n",
    "                                \"heter_frag_factor\": Input_heter_frag_factor\n",
    "                            })\n",
    "\n",
    "                        plt.xlabel(\"log(Size [µm])\")\n",
    "                        plt.ylabel(\"log(Relative Abundance [%])\")\n",
    "                        plt.title(f\"Overlay: {article_name} - {runName}\")\n",
    "                        plt.legend()\n",
    "                        plt.grid(True)\n",
    "                        plt.tight_layout()\n",
    "\n",
    "                        safe_article_name = article_name.replace(\" \", \"_\").replace(\"|\", \"_\").replace(\",\", \"\").replace(\".\", \"\")\n",
    "                        overlay_filename = f\"Overlay_{safe_article_name}_{runName}_{timestamp}.png\"\n",
    "                        overlay_path = os.path.join(overlay_plots_folder, overlay_filename)\n",
    "                        plt.savefig(overlay_path, bbox_inches=\"tight\")\n",
    "                        plt.close()\n",
    "\n",
    "                        # Fill mini plot path for last appended rows\n",
    "                        for row in reversed(comparison_rows):\n",
    "                            if row[\"Observed Dataset\"] == article_name and row[\"mini plot\"] == \"\":\n",
    "                                row[\"mini plot\"] = overlay_path\n",
    "                            else:\n",
    "                                if row[\"Observed Dataset\"] != article_name:\n",
    "                                    break\n",
    "\n",
    "                    print(f\"Completed run: {runName}\\n\")\n",
    "\n",
    "print(\"All iterations completed.\")\n",
    "\n",
    "#############################################\n",
    "# 9) EXPORT COMPARISON DATA TO EXCEL\n",
    "#############################################\n",
    "comparison_df = pd.DataFrame(comparison_rows)\n",
    "cols_order = [\n",
    "    \"Observed Dataset\", \"Model Compartment\",\n",
    "    \"Model slope\", \"Observed slope\",\n",
    "    \"Model intercept\", \"Observed intercept\",\n",
    "    \"Euclidean distance\", \"R-squared\", \"RMSE\", \"n_points\",\n",
    "    \"mini plot\", \"Emissions flow (g/s)\", \"Emitted MP density (kg/m3)\",\n",
    "    \"Receiving compartment/s\", \"Emitted MP form\", \"Emitted MP size (um)\",\n",
    "    \"frag_styles_dict\", \"t_half_deg_free\", \"heter_deg_factor\", \"biof_deg_factor\",\n",
    "    \"factor_deepWater_soilSurface\", \"factor_sediment\", \"t_frag_gen_FreeSurfaceWater\",\n",
    "    \"biof_frag_factor\", \"heter_frag_factor\"\n",
    "]\n",
    "\n",
    "for c in cols_order:\n",
    "    if c not in comparison_df.columns:\n",
    "        comparison_df[c] = np.nan\n",
    "comparison_df = comparison_df[cols_order]\n",
    "\n",
    "# Now append or create the file\n",
    "if os.path.exists(comparison_excel_file):\n",
    "    existing_df = pd.read_excel(comparison_excel_file)\n",
    "    combined_df = pd.concat([existing_df, comparison_df], ignore_index=True)\n",
    "    combined_df.to_excel(comparison_excel_file, index=False)\n",
    "else:\n",
    "    comparison_df.to_excel(comparison_excel_file, index=False)\n",
    "\n",
    "print(f\"Comparison data appended to '{comparison_excel_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
